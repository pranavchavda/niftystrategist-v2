"""Alerts service for price monitoring system.

Provides comprehensive alerting functionality including:
- Price alert data retrieval with filtering and sorting
- Sync operation management for Shopify products
- Scraping job coordination for competitors
- Product matching operation control
- Alert generation and MAP violation scanning
- Operation status monitoring and job tracking

Maintains compatibility with existing frontend expectations.
"""

from typing import Dict, List, Optional, Any
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, desc, asc, and_, or_, case
from sqlalchemy.orm import selectinload
from datetime import datetime, timedelta, timezone
from utils.datetime_utils import utc_now_naive
from decimal import Decimal
import uuid
import logging

from database.price_monitor_models import (
    PriceAlert, ProductMatch, IdcProduct, CompetitorProduct, Competitor,
    ScrapeJob, ViolationHistory
)
from database.session import get_db

logger = logging.getLogger(__name__)


class AlertsService:
    """Service for managing price alerts and monitoring operations."""
    
    def __init__(self):
        self.logger = logger.getChild(self.__class__.__name__)
    
    async def get_alerts_data(
        self,
        db: AsyncSession,
        status: str = 'active',
        severity: Optional[str] = None,
        limit: int = 50,
        brand: Optional[str] = None,
        competitor: Optional[str] = None,
        sort_by: str = 'recent'
    ) -> Dict[str, Any]:
        """Get alerts data with filtering and sorting.
        
        Args:
            db: Database session
            status: Alert status filter ('active', 'resolved', 'dismissed')
            severity: Severity filter ('minor', 'moderate', 'severe')
            limit: Maximum number of alerts to return
            brand: Brand name filter
            competitor: Competitor name filter
            sort_by: Sort option ('recent', 'severity', 'impact', 'oldest')
            
        Returns:
            Dict containing alerts, summary statistics, and applied filters
        """
        try:
            # Build where conditions
            conditions = []
            
            # Status filter
            if status == 'active':
                conditions.append(~PriceAlert.status.in_(['resolved', 'dismissed']))
            elif status == 'resolved':
                conditions.append(PriceAlert.status == 'resolved')
            elif status == 'dismissed':
                conditions.append(PriceAlert.status == 'dismissed')
            
            # Severity filter
            if severity:
                conditions.append(PriceAlert.severity == severity)
            
            # Build query
            query = select(PriceAlert).options(
                selectinload(PriceAlert.product_match).options(
                    selectinload(ProductMatch.idc_product),
                    selectinload(ProductMatch.competitor_product).options(
                        selectinload(CompetitorProduct.competitor)
                    )
                )
            )
            
            if conditions:
                query = query.where(and_(*conditions))
            
            # Brand/competitor filtering through joins
            if brand or competitor:
                query = query.join(ProductMatch)
                if brand:
                    query = query.join(ProductMatch.idc_product).where(
                        IdcProduct.vendor == brand
                    )
                if competitor:
                    query = query.join(ProductMatch.competitor_product).join(
                        CompetitorProduct.competitor
                    ).where(
                        func.lower(Competitor.name).contains(competitor.lower())
                    )
            
            # Sort options
            sort_options = {
                'recent': [desc(PriceAlert.created_at)],
                'severity': [desc(PriceAlert.severity), desc(PriceAlert.created_at)],
                'impact': [desc(PriceAlert.price_change)],
                'oldest': [asc(PriceAlert.created_at)]
            }
            
            query = query.order_by(*sort_options.get(sort_by, sort_options['recent']))
            query = query.limit(limit)
            
            # Execute query
            result = await db.execute(query)
            alerts = result.scalars().all()
            
            # Get alert count for summary
            count_query = select(func.count(PriceAlert.id))
            if conditions:
                count_query = count_query.where(and_(*conditions))
            
            count_result = await db.execute(count_query)
            total_count = count_result.scalar()
            
            if total_count == 0:
                return {
                    'alerts': [],
                    'summary': {
                        'total': 0,
                        'by_status': {},
                        'by_severity': {},
                        'total_impact': 0
                    },
                    'filters_applied': {
                        'status': status,
                        'severity': severity,
                        'brand': brand,
                        'competitor': competitor,
                        'sort_by': sort_by
                    },
                    'message': 'No alerts found in database - this is expected for a new installation'
                }
            
            # Clean up alert data for response
            cleaned_alerts = []
            for alert in alerts:
                alert_data = {
                    'id': alert.id,
                    'severity': alert.severity,
                    'status': alert.status,
                    'alert_type': alert.alert_type,
                    'price_change': float(alert.price_change) if alert.price_change else None,
                    'created_at': alert.created_at,
                    'updated_at': alert.updated_at,
                    'product_matches': None
                }
                
                if alert.product_match:
                    match = alert.product_match
                    alert_data['product_matches'] = {
                        'id': match.id,
                        'overall_score': float(match.overall_score) if match.overall_score else None,
                        'is_map_violation': match.is_map_violation,
                        'violation_amount': float(match.violation_amount) if match.violation_amount else None,
                        'violation_percentage': float(match.violation_percentage) if match.violation_percentage else None,
                        'idc_products': None,
                        'competitor_products': None
                    }
                    
                    if match.idc_product:
                        idc = match.idc_product
                        alert_data['product_matches']['idc_products'] = {
                            'id': idc.id,
                            'title': idc.title,
                            'vendor': idc.vendor,
                            'sku': idc.sku,
                            'price': float(idc.price) if idc.price else None,
                            'handle': idc.handle,
                            'product_type': idc.product_type,
                            'idc_url': f'https://idrinkcoffee.com/products/{idc.handle}' if idc.handle else None
                        }
                    
                    if match.competitor_product:
                        comp = match.competitor_product
                        alert_data['product_matches']['competitor_products'] = {
                            'id': comp.id,
                            'title': comp.title,
                            'price': float(comp.price) if comp.price else None,
                            'url': comp.product_url,
                            'competitor_url': comp.product_url or (
                                f'https://{comp.competitor.domain}/products/{comp.handle}' if comp.handle and comp.competitor else None
                            ),
                            'competitors': {
                                'id': comp.competitor.id,
                                'name': comp.competitor.name,
                                'domain': comp.competitor.domain
                            } if comp.competitor else None
                        }
                
                cleaned_alerts.append(alert_data)
            
            # Sort alerts by similarity score within severity levels
            cleaned_alerts.sort(key=lambda x: (
                {'severe': 3, 'moderate': 2, 'minor': 1}.get(x['severity'], 0),
                x['product_matches']['overall_score'] if x['product_matches'] and x['product_matches']['overall_score'] else 0
            ), reverse=True)
            
            # Get summary statistics
            summary_query = select(
                PriceAlert.severity,
                PriceAlert.status,
                func.count(PriceAlert.id).label('count'),
                func.sum(PriceAlert.price_change).label('total_change')
            ).group_by(PriceAlert.severity, PriceAlert.status)
            
            summary_result = await db.execute(summary_query)
            summary_rows = summary_result.all()
            
            # Format summary data
            summary_formatted = {
                'total': len(cleaned_alerts),
                'by_status': {},
                'by_severity': {},
                'total_impact': 0
            }
            
            for row in summary_rows:
                # By status
                if row.status not in summary_formatted['by_status']:
                    summary_formatted['by_status'][row.status] = 0
                summary_formatted['by_status'][row.status] += row.count
                
                # By severity (only for active alerts)
                if row.status not in ['resolved', 'dismissed']:
                    if row.severity not in summary_formatted['by_severity']:
                        summary_formatted['by_severity'][row.severity] = 0
                    summary_formatted['by_severity'][row.severity] += row.count
                
                # Total impact
                summary_formatted['total_impact'] += abs(float(row.total_change or 0))
            
            return {
                'alerts': cleaned_alerts,
                'summary': summary_formatted,
                'filters_applied': {
                    'status': status,
                    'severity': severity,
                    'brand': brand,
                    'competitor': competitor,
                    'sort_by': sort_by
                }
            }
            
        except Exception as e:
            self.logger.error(f'Error fetching alerts data: {e}')
            raise
    
    async def trigger_sync_operation(
        self,
        db: AsyncSession,
        brands: Optional[List[str]] = None,
        limit: int = 100
    ) -> Dict[str, Any]:
        """Trigger Shopify sync operation.
        
        Args:
            db: Database session
            brands: List of brands to sync (None for all)
            limit: Limit on products to sync
            
        Returns:
            Dict with sync results and job information
        """
        try:
            self.logger.info('Starting Shopify sync operation')
            
            sync_results = []
            
            # Create sync job record
            sync_job_data = {
                'id': str(uuid.uuid4()),
                'brands': brands or [],
                'limit': limit,
                'status': 'started',
                'started_at': utc_now_naive(),
                'updated_at': utc_now_naive()
            }
            
            if brands:
                for brand in brands:
                    sync_results.append({
                        'brand': brand,
                        'status': 'sync_initiated',
                        'message': f'Sync operation started for brand: {brand}',
                        'products_synced': 0,
                        'products_created': 0,
                        'products_updated': 0
                    })
            else:
                sync_results.append({
                    'brand': 'all_monitored_brands',
                    'status': 'sync_initiated',
                    'message': 'Sync operation started for all monitored brands',
                    'products_synced': 0,
                    'products_created': 0,
                    'products_updated': 0
                })
            
            total_synced = sum(r.get('products_synced', 0) for r in sync_results)
            total_created = sum(r.get('products_created', 0) for r in sync_results)
            total_updated = sum(r.get('products_updated', 0) for r in sync_results)
            
            self.logger.info(f'Sync completed: {total_synced} products synced, {total_created} created, {total_updated} updated')
            
            return {
                'message': 'Sync operation completed',
                'results': sync_results,
                'summary': {
                    'brands_synced': len(sync_results),
                    'total_products_synced': total_synced,
                    'total_products_created': total_created,
                    'total_products_updated': total_updated
                }
            }
            
        except Exception as e:
            self.logger.error(f'Error triggering sync operation: {e}')
            raise
    
    async def trigger_scraping_operation(
        self,
        db: AsyncSession,
        competitor_ids: Optional[List[str]] = None,
        collections: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Trigger competitor scraping operation.
        
        Args:
            db: Database session
            competitor_ids: List of competitor IDs to scrape
            collections: List of collections to scrape
            
        Returns:
            Dict with scraping job information
        """
        try:
            self.logger.info('Starting scraping operation')
            
            # Get competitors to scrape
            if competitor_ids:
                query = select(Competitor).where(
                    and_(
                        Competitor.id.in_(competitor_ids),
                        Competitor.is_active == True
                    )
                )
            else:
                query = select(Competitor).where(Competitor.is_active == True)
            
            result = await db.execute(query)
            competitors = result.scalars().all()
            
            if not competitors:
                raise ValueError('No active competitors found')
            
            jobs = []
            
            # Create scraping jobs
            for competitor in competitors:
                scrape_job = ScrapeJob(
                    id=str(uuid.uuid4()),
                    competitor_id=competitor.id,
                    collections=collections or competitor.collections,
                    status='running',
                    started_at=utc_now_naive(),
                    updated_at=utc_now_naive()
                )
                
                db.add(scrape_job)
                
                jobs.append({
                    'job_id': scrape_job.id,
                    'competitor': competitor.name,
                    'status': 'started'
                })
                
                self.logger.info(f'Created scraping job {scrape_job.id} for {competitor.name}')
            
            await db.commit()
            
            return {
                'message': f'Started scraping for {len(jobs)} competitors',
                'jobs': jobs
            }
            
        except Exception as e:
            self.logger.error(f'Error triggering scraping operation: {e}')
            raise
    
    async def trigger_product_matching(
        self,
        db: AsyncSession,
        brands: Optional[List[str]] = None,
        force_rematch: bool = False,
        confidence_threshold: float = 0.7
    ) -> Dict[str, Any]:
        """Trigger product matching operation.
        
        Args:
            db: Database session
            brands: List of brands to match
            force_rematch: Whether to force rematching existing matches
            confidence_threshold: Minimum confidence threshold
            
        Returns:
            Dict with matching results
        """
        try:
            self.logger.info('Starting product matching operation')
            
            matching_results = []
            
            if brands:
                for brand in brands:
                    matching_results.append({
                        'brand': brand,
                        'status': 'matching_initiated',
                        'message': f'Product matching started for brand: {brand}',
                        'matches_found': 0,
                        'matches_created': 0,
                        'confidence_threshold': confidence_threshold,
                        'force_rematch': force_rematch
                    })
            else:
                matching_results.append({
                    'brands': 'all_monitored_brands',
                    'status': 'matching_initiated',
                    'message': 'Product matching started for all monitored brands',
                    'matches_found': 0,
                    'matches_created': 0,
                    'confidence_threshold': confidence_threshold,
                    'force_rematch': force_rematch
                })
            
            total_matches = sum(r.get('matches_found', 0) for r in matching_results)
            total_created = sum(r.get('matches_created', 0) for r in matching_results)
            
            self.logger.info(f'Matching completed: {total_matches} matches found, {total_created} created')
            
            return {
                'message': 'Product matching operation completed',
                'results': matching_results,
                'summary': {
                    'total_matches_found': total_matches,
                    'total_matches_created': total_created,
                    'confidence_threshold': confidence_threshold
                }
            }
            
        except Exception as e:
            self.logger.error(f'Error triggering matching operation: {e}')
            raise
    
    async def generate_alerts(
        self,
        db: AsyncSession,
        brands: Optional[List[str]] = None,
        severity_filter: Optional[str] = None,
        create_alerts: bool = True,
        dry_run: bool = False
    ) -> Dict[str, Any]:
        """Generate new alerts by scanning for MAP violations.
        
        Args:
            db: Database session
            brands: List of brands to scan
            severity_filter: Filter by severity level
            create_alerts: Whether to create alert records
            dry_run: Whether this is a dry run
            
        Returns:
            Dict with scan results
        """
        try:
            self.logger.info('Starting alert generation (MAP violation scan)')
            
            # Call the actual violations scanner to detect and create alerts
            from services.price_monitor.violations import ViolationsService
            violations_service = ViolationsService()
            
            scan_results = await violations_service.scan_and_record_violations(
                db=db,
                brands=brands,
                severity_filter=severity_filter,
                record_history=True,
                capture_screenshots=False,
                dry_run=dry_run
            )
            
            # Create PriceAlert records for each violation found if create_alerts is True
            if create_alerts and not dry_run and scan_results.get('violations'):
                for violation in scan_results['violations']:
                    if violation.get('is_new'):  # Only create alerts for new violations
                        alert = PriceAlert(
                            id=str(uuid.uuid4()),
                            product_match_id=violation['match_id'],
                            alert_type=f"map_violation_{violation['violation']['severity']}",
                            title=violation['idc_product']['title'],
                            message=f"MAP violation detected: {violation['competitor_product']['competitor']} selling {violation['violation']['percentage']:.1f}% below MAP",
                            severity=violation['violation']['severity'],
                            old_price=Decimal(str(violation['idc_product']['price'])),  # MAP price
                            new_price=Decimal(str(violation['competitor_product']['price'])),  # Competitor price
                            price_change=Decimal(str(violation['violation']['amount'])),
                            status='active',
                            created_at=utc_now_naive(),
                            updated_at=utc_now_naive()
                        )
                        db.add(alert)
                
                await db.commit()
                self.logger.info(f"Created {len([v for v in scan_results['violations'] if v.get('is_new')])} new price alerts")
            
            # Modify the response to match what was expected
            scan_results['message'] = f'MAP violation scan completed{" (dry run)" if dry_run else ""}'
            scan_results['filters'] = {
                'brands': brands or 'all_monitored_brands',
                'severity_filter': severity_filter or 'all_severities',
                'create_alerts': create_alerts,
                'dry_run': dry_run
            }
            
            self.logger.info(f'Alert generation completed: {scan_results["violations_found"]} violations found')
            
            return {
                'message': f'Alert generation completed{" (dry run)" if dry_run else ""}',
                **scan_results
            }
            
        except Exception as e:
            self.logger.error(f'Error generating alerts: {e}')
            raise
    
    async def get_operation_status(
        self,
        db: AsyncSession,
        operation_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """Get operation status for various monitoring operations.
        
        Args:
            db: Database session
            operation_type: Type of operation to check ('sync', 'scrape', 'alerts')
            
        Returns:
            Dict with operation status information
        """
        try:
            status = {}
            
            if not operation_type or operation_type == 'scrape':
                # Check recent scraping operations
                query = select(ScrapeJob).options(
                    selectinload(ScrapeJob.competitor)
                ).order_by(desc(ScrapeJob.created_at)).limit(5)
                
                result = await db.execute(query)
                recent_jobs = result.scalars().all()
                
                status['scrape'] = {
                    'recent_jobs': [
                        {
                            'id': job.id,
                            'competitor': job.competitor.name if job.competitor else None,
                            'status': job.status,
                            'products_found': job.products_found,
                            'started_at': job.started_at,
                            'completed_at': job.completed_at
                        } for job in recent_jobs
                    ],
                    'active_jobs': len([j for j in recent_jobs if j.status == 'running'])
                }
            
            if not operation_type or operation_type == 'alerts':
                # Check alerts summary
                summary_query = select(
                    PriceAlert.status,
                    PriceAlert.severity,
                    func.count(PriceAlert.id).label('count')
                ).group_by(PriceAlert.status, PriceAlert.severity)
                
                result = await db.execute(summary_query)
                summary_rows = result.all()
                
                alerts_formatted = {
                    'active': 0,
                    'resolved': 0,
                    'dismissed': 0,
                    'by_severity': {}
                }
                
                for row in summary_rows:
                    if row.status == 'resolved':
                        alerts_formatted['resolved'] += row.count
                    elif row.status == 'dismissed':
                        alerts_formatted['dismissed'] += row.count
                    else:
                        alerts_formatted['active'] += row.count
                        if row.severity not in alerts_formatted['by_severity']:
                            alerts_formatted['by_severity'][row.severity] = 0
                        alerts_formatted['by_severity'][row.severity] += row.count
                
                status['alerts'] = alerts_formatted
            
            return {
                'timestamp': utc_now_naive().isoformat(),
                'status': status
            }
            
        except Exception as e:
            self.logger.error(f'Error fetching operation status: {e}')
            raise
